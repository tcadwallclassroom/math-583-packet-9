---
title: "Packet 9 - Numerical Inference Lightning Round"
knit: (function(input_file, encoding) {
  out_dir <- 'docs';
  rmarkdown::render(input_file,
  encoding=encoding,
  output_file=file.path(dirname(input_file), out_dir, 'index.html'))})
author: "Todd CadwalladerOlsker"
date: "*Last updated:* `r Sys.Date()`"
output:
  rmdformats::downcute:
    downcute_theme: "chaos"
editor_options: 
  chunk_output_type: console
---

```{r setup, include=FALSE}
library(rmdformats)
library(openintro)
library(tidyverse)
library(gghighlight)
library(formatR)
library(infer)
library(gssr)
knitr::opts_chunk$set(echo = T, 
                      cache = T, 
                      eval = T, 
                      cache.lazy = F, 
                      warning = F)
knitr::opts_chunk$set(tidy.opts=list(width.cutoff=80),tidy=F)
options(scipen = 999)
```

## Test for Inference on Numeric Variables

We'll start by loading up some data from the GSS:

```{r gss18}
num_vars <- c("age", "coninc", "hrs1")
cat_vars <- c("sex", "satfin", "class", "wrkstat")
my_vars <- c(num_vars, cat_vars)

gss18 <- gss_get_yr(2018)
gss_data <- gss18
gss_data <- gss_data %>% 
  select(all_of(my_vars)) %>% 
  mutate(
    across(everything(), haven::zap_missing),
    across(all_of(cat_vars), forcats::as_factor)
  ) %>% 
  mutate(
    across(all_of(num_vars), as.numeric)
  ) ## GGS numeric variables don't play nicely with infer.
```

The `hrs1` variable records how many hours the respondent worked in the previous week. 

Let's examine the data before doing anything else:

```{r}
gss_data %>% 
  drop_na(hrs1) %>% 
  summarize(mean = mean(hrs1),
            sd = sd(hrs1),
            median = median(hrs1)
            )

gss_data %>% ggplot(aes(x = hrs1)) + 
  geom_histogram(color = "black",
                 fill = "forestgreen",
                 bins = 20)
```


Let's find the mean for our sample:

```{r hrs1 mean}
x_bar <- gss_data %>% 
  specify(response = hrs1) %>%
  calculate(stat = "mean")
x_bar
```

We can bootstrap a confidence interval for a range estimate:

```{r hrs1 ci}
boot_dist <- gss_data %>%
  specify(response = hrs1) %>%
  generate(reps = 10000, type = "bootstrap") %>%
  calculate(stat = "mean")

percentile_ci <- get_ci(boot_dist, level = 0.95)
percentile_ci

boot_dist %>% visualize(bins = 30) +
  shade_confidence_interval(endpoints = percentile_ci)
```

Let's test the claim that the average American works more than 40 hours per week. That is, we are testing the null hypothesis that $\mu = 40$ and the alternative that $\mu > 40$. We'll do this by again bootstrapping our data, to estimate the variance.

```{r hrs1 rando test}
null_dist <- gss_data %>%
  specify(response = hrs1) %>%
  hypothesize(null = "point", mu = 40) %>%
  generate(reps = 10000, type = "bootstrap") %>%
  calculate(stat = "mean")

null_dist %>% visualize(bins = 30) +
  shade_p_value(obs_stat = x_bar, direction = "greater")

null_dist %>%
  get_p_value(obs_stat = x_bar, direction = "greater")
```

The "theoretical distribution" for a sample mean is the *t-statistic*. The idea is that we can't directly compute the z-score, since we don't know the standard deviation $\sigma$. Instead, we can only approximate the standard error with $s$, the sample standard deviation:

\[SE = \frac{\sigma}{\sqrt{n}} \approx \frac{s}{\sqrt{n}} \]

The t-score is calculated the same as a z-score:

\[t = \frac{\bar{x}-\mu}{SE}\]

Because the SE is calculated with $s$ rather than $\sigma$, there is a bit more variability in the t-distribution compared to the normal (z-) distribution. In other words, the t-distribution has a slightly lower peak and slightly fatter tails than the normal distribution. (See Introduction to Modern Statistics, p. 362.) The more data we have, the more degrees of freedom in the t-distribution, and the more the t-distribution resembles a normal curve.

We can have `infer` calculate a t-statistic, and compute a null distribution based on t as well:

```{r}
t <- gss_data %>% 
  specify(response = hrs1) %>%
  calculate(stat = "t", mu = 40)
t

null_dist <- gss_data %>%
  specify(response = hrs1) %>%
  hypothesize(null = "point", mu = 40) %>%
  generate(reps = 10000, type = "bootstrap") %>%
  calculate(stat = "t")

null_dist %>% visualize(method = "both", bins = 30) +
  shade_p_value(obs_stat = t, direction = "greater")

null_dist %>%
  get_p_value(obs_stat = t, direction = "greater")
```

The theoretical t-test can also be run with an R function:

```{r}
ttest1 <- t.test(gss_data$hrs1, mu = 40, alternative = "greater")
ttest1
ttest2 <- gss_data %>% 
  t_test(hrs1 ~ NULL, alternative = "greater")
ttest2
```

As an aside, we can also test hypotheses involving the median. This is especially useful with highly skewed data. We don't have a "t-distribution" for the median, but we can still perform a randomization test:

```{r}
x_tilde <- gss_data %>% 
  specify(response = hrs1) %>%
  calculate(stat = "median")
x_tilde

null_dist <- gss_data %>%
  specify(response = hrs1) %>%
  hypothesize(null = "point", med = 40) %>%
  generate(reps = 10000, type = "bootstrap") %>%
  calculate(stat = "median")

null_dist %>% visualize(bins = 30) +
  shade_p_value(obs_stat = x_tilde, direction = "greater")

null_dist %>%
  get_p_value(obs_stat = x_tilde, direction = "greater")
```

What do you notice/wonder about our results?

## Wildly non-normal data

Let's do the same thing with the `poker` dataset from the OpenIntro package:

```{r poker, eval=FALSE}
library(openintro)
help("poker")
glimpse(poker)
```

The `winnings` variable indicates the amount of money won by a professional poker player on 50 randomply chosen days.

Let's examine the data before doing anything else:

```{r}
poker %>% 
  drop_na(winnings) %>% 
  summarize(mean = mean(winnings),
            sd = sd(winnings),
            median = median(winnings)
            )

poker %>% ggplot(aes(x = winnings)) + 
  geom_histogram(color = "black",
                 fill = "forestgreen",
                 bins = 30) +
  labs(
    x = "Winnings",
    y = "Number of Days in Sample"
  )

```


Let's find the mean for our sample:

```{r poker mean}
x_bar <- poker %>% 
  specify(response = winnings) %>%
  calculate(stat = "mean")
x_bar
```

We can bootstrap a confidence interval for a range estimate:

```{r poker ci}

boot_dist <- poker %>%
  specify(response = winnings) %>%
  generate(reps = 10000, type = "bootstrap") %>%
  calculate(stat = "mean")

percentile_ci <- get_ci(boot_dist)
percentile_ci

boot_dist %>% visualize(bins = 30) +
  shade_confidence_interval(endpoints = percentile_ci)
```

Let's test the claim that the average winnings are over \$0 (that is, the professional poker player is actually making money!). That is, we are testing the null hypothesis that $\mu = 0$ and the alternative that $\mu > 0$. We'll do this by again bootstrapping our data, to estimate the variance.

```{r poker rando test}
null_dist <- poker %>%
  specify(response = winnings) %>%
  hypothesize(null = "point", mu = 0) %>%
  generate(reps = 10000, type = "bootstrap") %>%
  calculate(stat = "mean")

null_dist %>% visualize(bins = 30) +
  shade_p_value(obs_stat = x_bar, direction = "greater")

null_dist %>%
  get_p_value(obs_stat = x_bar, direction = "greater")
```

Let's see what we get from the t-statistic, and compute a null distribution based on t as well:

```{r}
t <- poker %>% 
  specify(response = winnings) %>%
  calculate(stat = "t", mu = 0)
t

null_dist <- poker %>% 
  specify(response = winnings) %>%
  hypothesize(null = "point", mu = 0) %>%
  generate(reps = 10000, type = "bootstrap") %>%
  calculate(stat = "t")

null_dist %>% visualize(method = "both",bins = 30) +
  shade_p_value(obs_stat = t, direction = "greater")

null_dist %>%
  get_p_value(obs_stat = t, direction = "greater")
```

What do you notice/wonder?

## T-test for paired data

Take a look at the `textbooks` data set in `openintro`. We are interested in the question, "Are textbooks more expensive at the UCLA bookstore than they are at Amazon?"

```{r}
x_bar <- textbooks %>% 
  specify(response = diff) %>% 
  calculate(stat = "mean")
x_bar

null_dist <- textbooks %>% 
  specify(response = diff) %>%
  hypothesize(null = "point", mu = 0) %>% 
  generate(reps = 10000, type = "bootstrap") %>% 
  calculate(stat = "mean")

null_dist %>% visualise(bins = 30)+
  shade_p_value(obs_stat = x_bar, direction = "two-sided")

null_dist %>% get_p_value(obs_stat = x_bar, direction = "two-sided")
```


## Difference in means

Look at the `ncbirths` data set in the `openintro` package. View the data and help file to get a sense of what this data set contains. We are interested in the question, "Is the average weight of babies born to mothers who smoke different than that of babies born to mothers who do not?"

Before trying to run any analysis, calculate the mean weight for each group, then create a set of stacked boxplots for the weights of each group. 

Now, we can use the `infer` package to run tests similar to the above: The big difference is that we will have both a response variable *and* an explanatory variable. Let's start with a confidence interval for the *mean difference between the groups*: 

```{r}
ncbirths <- ncbirths %>% 
  drop_na(weight, habit)

ncb_d_hat <- ncbirths %>% 
  specify(response = weight, explanatory = habit) %>%
  calculate(stat = "diff in means", order = c("smoker", "nonsmoker"))
ncb_d_hat

### Bootstrap Conf. Interval

ncb_boot_dist_d_hat <- ncbirths %>%
  specify(response = weight, explanatory = habit) %>%
  generate(reps = 10000, type = "bootstrap") %>%
  calculate(stat = "diff in means", order = c("smoker", "nonsmoker"))

ncb_percentile_ci <- get_ci(ncb_boot_dist_d_hat, level = 0.95)
ncb_percentile_ci

ncb_boot_dist_d_hat %>% visualize(bins = 30) +
  shade_confidence_interval(endpoints = ncb_percentile_ci)

```

Now, we can calculate the t statistic, to see how unusual this difference is. Here we want to find the t-score of the difference between the groups, to see if it is different from 0. The t-statistic is the mean of the difference between the two groups, minus 0 (the null hypothesis is that the difference is 0), divided by the standard error, where:

\[SE = \sqrt{\frac{s_1^2}{n_1}+\frac{s_2^2}{n_2}}\]

```{r}

ncb_t_hat <- ncbirths %>% 
  specify(response = weight, explanatory = habit) %>%
  calculate(stat = "t", order = c("smoker", "nonsmoker"))
ncb_t_hat

ncb_null_dist_t <- ncbirths %>%
  specify(response = weight, explanatory = habit) %>%
  hypothesise(null = "independence") %>% 
  generate(reps = 10000, type = "permute") %>% 
  calculate(stat = "t", order = c("smoker", "nonsmoker"))

ncb_null_dist_t %>% visualise(bins = 30, method = "both") +
  shade_p_value(obs_stat = ncb_t_hat, direction = "two-sided")

ncb_null_dist_t %>% 
  get_p_value(obs_stat = ncb_t_hat, direction = "two-sided")
```



## GSS Example

Here's another possible question: are unemployed/laid off workers younger, on average, than full-time workers? We can calculate a *difference in means* for these groups, and determine if the difference is significant:

```{r}
gss_data <- gss_data %>% 
  drop_na(age)

gss_data %>% 
  group_by(wrkstat) %>% 
  summarise(mean_age = mean(age))

gss_data %>% filter(wrkstat == "working fulltime") %>% 
  summarize(mean_age = mean(age))

gss_data %>% filter(wrkstat == "unempl, laid off") %>% 
  summarize(mean_age = mean(age))

gss_data %>% filter(wrkstat == "working fulltime" |
                  wrkstat == "unempl, laid off") %>% 
  ggplot(aes(x = age)) +
  geom_histogram(aes(fill = wrkstat),
                 color = "black",
                 binwidth = 2,
                 alpha = 0.5,
                 position = "identity") +
  scale_fill_brewer(palette = "Dark2") +
  labs(
    x = "Age",
    y = "Number of respondents",
    fill = "Work Status"
  )
```

Using `infer`:

```{r}

gss_data_twogroups <- gss_data %>% 
  filter(wrkstat == "working fulltime" |
         wrkstat == "unempl, laid off") %>% 
  droplevels()

table(gss_data_twogroups$wrkstat)

gss_d_hat <- gss_data_twogroups %>% 
  specify(response = age, explanatory = wrkstat) %>%
  calculate(stat = "diff in means")
gss_d_hat

### Bootstrap Conf. Interval

gss_boot_dist_d_hat <- gss_data_twogroups %>%
  specify(response = age, explanatory = wrkstat) %>%
  generate(reps = 10000, type = "bootstrap") %>%
  calculate(stat = "diff in means")

gss_percentile_ci <- get_ci(gss_boot_dist_d_hat, level = 0.95)
gss_percentile_ci

gss_boot_dist_d_hat %>% visualize(bins = 30) +
  shade_confidence_interval(endpoints = gss_percentile_ci)

### T-test:

gss_t_hat <- gss_data_twogroups %>% 
  specify(response = age, explanatory = wrkstat) %>%
  calculate(stat = "t")
gss_t_hat

null_dist_t <- gss_data_twogroups %>%
  specify(response = age, explanatory = wrkstat) %>%
  hypothesise(null = "independence") %>% 
  generate(reps = 10000, type = "permute") %>%
  calculate(stat = "t")

null_dist_t %>% visualise(bins = 30, method = "both") +
  shade_p_value(obs_stat = gss_t_hat, direction = "two-sided")

null_dist_t %>% 
  get_p_value(obs_stat = gss_t_hat, direction = "two-sided")
```



## Analysis of Variance (ANOVA)

Look again at the GSS data on work status and age. Rather than examine each pair of groups, we want to test the null hypothesis of whther these two variables are independent across all the groups. In order ot examine this, we'll conduct an Analysis of Variance, also known as an ANOVA or F-test.

The test statistic, F, is defined as the *ratio of the mean square between groups (MSG) and the mean square error (MSE)*. :

\begin{align*}
F &= \frac{MSG}{MSE}
\end{align}

Both MSE and MSG are complicated to calculate, but roughly speaking, MSG is the variance *between* group means, where MSE is the variance *within*  groups. 

```{r}
gss_F_stat <- gss_data %>% 
  specify(response = age, explanatory = wrkstat) %>% 
  calculate(stat = "F")

gss_F_null_dist<- gss_data %>% 
  specify(response = age, explanatory = wrkstat) %>% 
  hypothesise(null = "independence") %>% 
  generate(reps = 10000, type = "permute") %>% 
  calculate(stat = "F")

gss_F_null_dist %>% visualise(bins = 30, method = "both") +
  shade_p_value(obs_stat = gss_F_stat, direction = "greater")

gss_F_null_dist %>% 
  get_p_value(obs_stat = gss_F_stat, direction = "greater")
```

You can run an ANOVA in R using the code:

```{r}
gss_data %>% 
    group_by(wrkstat) %>% 
    summarise(mean_age = mean(age))

gss_model <- lm(age ~ wrkstat, data = gss_data)
gss_model
anova(gss_model)
```

Try running similar tests with the `classdata` set from `openintro`.